# Безопасность и Оценка (Safety & Evaluation)

Для создания надежной и предсказуемой AI-системы недостаточно просто реализовать основной функционал. В **PyAgentX** мы внедрили два критически важных компонента, которые обеспечивают контроль качества и безопасность работы агентов.

### 1. Ограничения (Guardrails)

Чтобы предотвратить нежелательное или вредоносное поведение агентов, мы используем механизм "ограждений" с помощью библиотеки `guardrails-ai`.

**`GuardrailManager` (`app/safety/guardrails.py`)** выступает в роли модератора, который проверяет финальный ответ, сгенерированный системой, перед тем как показать его пользователю.

**Как это работает:**
-   Мы определяем набор правил (например, в формате `RAIL`, `*.rail`). В этих правилах мы можем указать, например, что ответ не должен касаться определенных тем (политика, финансы, вредные советы) или что он должен быть в определенном формате.
-   `GuardrailManager` "оборачивает" финальный вывод LLM в эти правила.
-   Если ответ соответствует всем правилам, он передается пользователю.
-   Если ответ нарушает хотя бы одно правило, система может либо заблокировать его, либо попытаться "исправить" (например, убрав запрещенный контент), либо вернуть стандартизированное сообщение о том, что запрос не может быть выполнен.

Это обеспечивает дополнительный слой безопасности и контроля над поведением AI.

### 2. Оценка (Evaluation)

Чтобы объективно измерять качество и производительность нашей системы, мы используем фреймворк для тестирования и оценки **`deepeval`**. Это позволяет нам не полагаться на субъективные ощущения, а иметь конкретные метрики.

**`tests/test_agent_evaluation.py`** содержит набор тестов, которые прогоняют систему через заранее определенные сценарии и оценивают результаты по ряду критериев:

-   **Answer Relevancy**: Насколько ответ агента релевантен исходному запросу?
-   **Faithfulness**: Насколько ответ соответствует извлеченному из базы знаний контексту? (Не "галлюцинирует" ли агент?)
-   **Contextual Recall**: Насколько полно ретривер извлек всю необходимую информацию из базы знаний для ответа на вопрос?

**Зачем это нужно:**
-   **Объективное измерение качества**: Мы получаем числовые метрики, которые показывают, насколько хорошо система справляется со своими задачами.
-   **Обнаружение регрессий**: Запуская эти тесты после каждого значительного изменения в коде, мы можем быть уверены, что не "сломали" то, что уже работало. Если метрики падают, это сигнал о проблеме.
-   **Сравнение подходов**: Мы можем использовать этот фреймворк для A/B тестирования различных моделей, промптов или конфигураций RAG, чтобы выбрать наиболее эффективные.

[Вернуться к README](../README.md) 