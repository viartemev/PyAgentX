# Продвинутый RAG-пайплайн (Advanced RAG)

Для того чтобы агенты **PyAgentX** могли принимать решения, основанные на актуальных данных и контексте проекта, мы реализовали многоступенчатый RAG-пайплайн (Retrieval-Augmented Generation). Он нацелен на извлечение максимально релевантной информации из базы знаний.

Пайплайн состоит из трех ключевых этапов:

### 1. Семантическое чанкирование (Semantic Chunking)

На этапе построения базы знаний (`scripts/build_knowledge_base.py`) мы отказались от наивного разделения текста на фрагменты (чанки) фиксированной длины. Вместо этого мы используем **семантический подход** с помощью библиотеки `semchunk`.

Алгоритм анализирует семантическую близость между соседними предложениями и "разрезает" текст в тех местах, где происходит смена темы. Это позволяет нам получать на выходе осмысленные, логически завершенные чанки, которые содержат целостный контекст. Такой подход значительно повышает качество информации, которую мы сможем извлечь на последующих этапах.

### 2. Двухэтапный гибридный поиск (Two-stage Hybrid Retrieval)

Когда агенту требуется информация, наш ретривер (`app/rag/retriever.py`) запускает двухэтапный поиск для нахождения наиболее релевантных чанков:

1.  **Этап 1: Быстрый отбор кандидатов**. Мы одновременно используем два метода поиска, чтобы получить широкий пул потенциально релевантных документов:
    *   **Dense (Векторный) поиск**: Находит чанки, близкие к запросу по **смыслу**, даже если в них нет точных ключевых слов. Идеально подходит для поиска концепций и идей.
    *   **Sparse (Ключевой) поиск (BM25)**: Находит чанки, содержащие точные **ключевые слова** из запроса. Идеально подходит для поиска конкретных терминов, функций или имен переменных.

Результаты обоих поисков объединяются для формирования списка из ~25 лучших кандидатов.

### 3. Переранжирование с помощью Cross-Encoder (Cross-Encoder Re-ranking)

2.  **Этап 2: Точное переранжирование**. Получив список кандидатов, мы передаем его на вход более мощной, но и более медленной модели — **Cross-Encoder** (`sentence-transformers`).

В отличие от стандартных моделей, которые создают векторы для запроса и чанка по отдельности, Cross-Encoder получает на вход **пару (запрос, чанк)** и оценивает степень их релевантности напрямую. Это позволяет ему улавливать гораздо более тонкие смысловые связи.

Модель детально анализирует каждого кандидата в контексте исходного запроса и пересортировывает список, помещая на самые верхние позиции наиболее релевантные чанки.

В итоге агент получает не просто набор разрозненных фактов, а короткий, но максимально концентрированный и релевантный контекст для принятия решения.

[Вернуться к README](../README.md) 